###
### name  : דוד בורג
### ID    : [מספר תעודת זהות]
### course: אפידמיולוגיה (HIT.ac.il)
### lesson: רגרסיה לוגיסטית 06   
### date  : 13/07/2025
###  
###  נלמד לעשות רגסיה לוגיסטית


## Reset memory
```{r setup-packages, include = FALSE}
rm(list = ls(all.names = TRUE))       # 👈 Clear all data objects        👇 Clear packages
lapply(paste("package:", names(sessionInfo()$otherPkgs), sep = ""), detach, character.only = TRUE, unload = TRUE, force = TRUE)           # Remove packages from memory
gc()                                  # Clear unused data from memory ("garbage cllection")
dev.off()                             # Reset the display output of R
q("no")                               # This will completely shutdown R terminal
```

## Load required packages
```{r load-packages, include = FALSE}
options("install.lock" = FALSE)
if (!require("pacman")) install.packages("pacman") ; library(pacman)
pacman::p_load(
  Rcpp, devtools, gh, remotes,   # For installing packages/files online (like from GitHub)
  rio, here,              # File import and path support
  labelled,               # deal with labels
  tidyverse,              # data management + ggplot2 graphics,
  broom,                  # For tidying model outputs
  dplyr,                  # For data manipulation
  gt,                     # Nice beuatiful tables
  gtsummary,              # summary statistics and tests
  nortest,                # Anderson-Darling test for normality
  ggplot2,                # For creating plots
  ggpubr,                 # For ggplot2 extensions
  DescTools,              # For statistical functions like skewness and kurtosis
  summarytools,           # to get a table of all summary statistics
  car,                    # For Levene's test and ANOVA
  lmtest,                 # do linear regression tests
  parameters,             # get standardized parameters/coefficients
  GGally,                 # to make a correlation matrix
  skimr,                  # get overview of data
  pROC,                   # For ROC analysis
  caret,                  # For confusion matrix and classification metrics
  ggeffects,              # To display the confusion matrix
  performance,            # For model performance metrics
  ResourceSelection       # For Hosmer-Lemeshow test for goodness of fit 
              )
# Install/load flexplot
if (!require("flexplot", quietly = TRUE)) devtools::install_github("dustinfife/flexplot", ref = "logistic_plots")  ;  gt(labels)
```

## Access the data
```{r read-data, echo = TRUE}
# file <- "./EpiData/04 stroke.rds"     # 👈 use this if the file is on your computer
file <- "https://raw.githubusercontent.com/Model-Lab-Net/Courses/refs/heads/main/Epi/Data/04%20stroke.rds"
df3 <- import(file, trust = TRUE)
# show variable translations to Hebrew in lables
labels <- data.frame(Variable = names(df3), Label = unlist(var_label(df3)))   ;   gt(labels)
glimpse(df3)               # get an overview of the data
```

## Summary statistics
```{r clean-data, echo = TRUE}
# Get summary statistics
df3 %>%
  tbl_summary(by = status) %>%
  as_gt()
```

## Logistic regression
```{r logistic-reg, echo = TRUE}
# Perform logistic regression
log_reg <- glm(status ~ gcs, data = df3, family = binomial(link = "logit"))
tidy(log_reg, conf.int = TRUE)
```

## Plot data and model
```{r flexplot, echo = TRUE}
# use flexplot
flexplot(status ~ gcs, data = df3, method = "logistic", se = TRUE, jitter = c(0.1, 0.1))
magnet_plot(status ~ gcs, data = df3, dot_size=3)
logistic_overlay(status ~ gcs, data = df3, n_bins=13)
```

## Model performance measures
```{r model-performance, echo = TRUE}
# Get -2LL and AIC
minus_2LL_log_reg <- -2 * as.numeric(logLik(log_reg))
AIC_val <- AIC(log_reg)

# Calculate Nagelkerke's R²
r2_val <- PseudoR2(log_reg, which = "Nagelkerke")

# Chi-square statistic for the omnibus test
null_model <- glm(status ~ 1, data = df3, family = binomial(link = "logit")) # null model (intercept-only model)
model_perf <- anova(null_model, log_reg, test = "Chisq")
chi_sq <- model_perf$Deviance[2] # Chi-square statistic
p_val <- model_perf$`Pr(>Chi)`[2] # p-value

# Disiplay the summary of the logistic regression model
summary(log_reg)
paste("R²= ", r2_val)
```

# Calculate log OR
```{r calc-log_OR, echo = TRUE}
log_reg_tbl <- tbl_regression(log_reg, exponentiate = FALSE)
log_reg_tbl
```

# Calculate OR
```{r calc-OR, include=FALSE}
log_reg_OR <- tbl_regression(log_reg, exponentiate = TRUE)
log_reg_OR
```

# Combine logOR and OR results with model performance 
```{r log_reg_tbl, echo = TRUE}
combined_tbl <- tbl_merge(
  tbls = list(log_reg_tbl, log_reg_OR),
  tab_spanner = c("**log Odds**", "**Odds Ratio**") # Optional: Add spanning headers
) %>%
  as_gt() %>%
  tab_source_note(
    source_note = paste0(
      "R² = ", round(r2_val, 3),
      ", -2LL = ", round(minus_2LL_log_reg, 0),
      ",  AIC = ", round(AIC_val, 0),
      ",  χ² = ", round(chi_sq, 0),
      ",  p = ", round(p_val, 5)
    )
  )

# Display the combined table
combined_tbl
```

## Get better estimates
```{r log_reg-est, echo = TRUE}
estimates(log_reg)
```

## Evalute model prediction
```{r log_reg-eval, echo = TRUE}
# Calculate predicted probabilities and append to th df
df3$predict_prob <- predict(log_reg, type = "response")
df3$predict.prob <- as.integer(df3$predict_prob > 0.5)
glimpse(df3)

# Calculate the "confusion_matrix"
confusion_matrix <- caret::confusionMatrix(data = as.factor(round(df3$predict.prob, 2)), reference = as.factor(df3$status))
confusion_matrix

# Extract the confusion matrix table
cm_table <- as.data.frame(confusion_matrix$table)
colnames(cm_table) <- c("Predicted", "True", "Count")
cm_table <- cm_table %>%
  mutate(Percent = round(Count / sum(Count) * 100, 1))

# Plot confusion matrix as a heatmap
ggplot(data = cm_table, aes(x = Predicted, y = True, fill = Percent)) +
  geom_tile() +
  geom_text(aes(label = Percent), vjust = 0.5, color = "black") +
  scale_fill_gradient(low = "white", high = "blue") +
  theme_minimal() +
  labs(title = "Confusion Matrix", x = "Predicted", y = "True") +
  theme(axis.text.x = element_text(angle = 0, hjust = 1))

# Displayt model/cm metrics
cm_metrics_df <- data.frame(
  Metric = c("Accuracy", "PPV", "NPV", "Sensitivity", "Specificity", "Precision", "F1 Score"),
  Value = round(c(
    confusion_matrix$overall["Accuracy"],
    confusion_matrix$byClass["Pos Pred Value"],
    confusion_matrix$byClass["Neg Pred Value"],
    confusion_matrix$byClass["Sensitivity"],
    confusion_matrix$byClass["Specificity"],
    confusion_matrix$byClass["Precision"],
    confusion_matrix$byClass["F1"]
  ), 2)
)
cm_metrics_df

cm_metrics_df %>%
  gt() 
```

## Hosmer-Lemeshow test for GOF
```{r , echo=FALSE}
# Use generalhoslem to get the Hosmer–Lemeshow test result
hl_test <- hoslem.test(df3$status, df3$predict_prob, g=3)
hl_test
```

## ROC curve and AUC
```{r logistic_regression,2 echo = TRUE}
# Calculates the ROC curve
roc_obj <- roc(df3$status, df3$predict_prob)

# Plot ROC curve
plot(roc_obj, col = "blue", main = "ROC Curve")

# Print AUC (AUC > 0.7)
auc(roc_obj)
```





### -------------------------------------------------
## תרגול-עצמי

## שאלה 1
```{r question-1, echo = TRUE}
# 

```

## שאלה 2
```{r question-2, echo = TRUE}
# 

```

## שאלה 3
```{r question-3, echo = TRUE}
# 

```








### source: https://bookdown.org/drki_musa/dataanalysis/binary-logistic-regression.html
###         https://github.com/drkamarul/multivar_data_analysis/tree/main/data

## Clean the data
```{r clean-data, echo = TRUE}
# Load the data
file <- "https://raw.githubusercontent.com/drkamarul/multivar_data_analysis/refs/heads/main/data/stroke.dta"
df3 <- import(file, trust = TRUE)
#write.csv(df3, here("EpiData", "04 stroke.csv"))

# Clean up variable names
df3 <- clean_names(df3)
names(df3) <- gsub("_", ".", names(df3))

# Convert status to integer (2 -> 0, 1 -> 1)
df3 <- df3 %>%
  mutate(
    status = ifelse(status == 2, 0, 1),
    sex = ifelse(sex == 2, 0, 1)
  )

# Convert these variables from dbl to int
df3 <- df3 %>%
  mutate(across(c(sex, status, dm, stroke.type), as.integer))

# Check the updated dataset structure
glimpse(df3)

# Save as R data file
saveRDS(df3, here("EpiData", "04 stroke.rds"))
```

## Give variable explanations in labels
```{r labels, echo = TRUE}
attr(df3$sex, "label") <- "מגדר"
attr(df3$status, "label") <- "מצב (חי / נפטר)"
attr(df3$gcs, "label") <- "סולם התרדמת של גלאזגו"
attr(df3$sbp, "label") <- "לחץ דם סיסטולי"
attr(df3$dm , "label") <- "סוּכֶּרֶת"
attr(df3$age, "label") <- "גיל"
attr(df3$stroke.type, "label") <- "סוג שבץ מוח (HS / IS)"

labels <- NULL
labels <- data.frame(Variable = names(df3), Label = unlist(var_label(df3)))
gt(labels)
```
