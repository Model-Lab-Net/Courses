###
### name:  专
### ID  : [住驻专 转注转 转]
### course: 驻 (HIT.ac.il)
### lesson: 专专住 住转 06   
### date  : 15/06/2025
###  
###   注砖转 专住 住转 专 砖转
###
### source: https://github.com/drkamarul/multivar_data_analysis/tree/main/data


## Reset memory
```{r setup-packages, include = FALSE}
rm(list = ls(all.names = TRUE))
lapply(paste('package:',names(sessionInfo()$otherPkgs),sep=""),detach,character.only=TRUE,unload=TRUE,force=TRUE)
gc()
dev.off()
```

## Load required packages
```{r load-packages, include = FALSE}
options("install.lock"=FALSE)
if (!require("pacman")) install.packages("pacman")
library(pacman)
pacman::p_load(
  rio,          # File import
  tidyverse,    # data management + ggplot2 graphics, 
  gt,           # Nice beuatiful tables
  nortest,      # Anderson-Darling test for normality
  ggplot2,      # For creating plots
  DescTools,    # For statistical functions like skewness and kurtosis
  janitor,      # adding totals and percents to tables
  car,           # For Levene's test and ANOVA
  gtsummary,    # summary statistics and tests
  corrr,        # correlation analayis for numeric variables
  lmtest,
  dplyr,        # For data manipulation
  reshape2,     # For reshaping data
  skimr,        # get overview of data
  performance,           # For model performance metrics
  ResourceSelection,     # For goodness of fit tests
  broom,                 # For tidying model outputs
  VGAM,
  pROC,                  # For ROC analysis
  caret                  # For confusion matrix and classification metrics
            )
#library(LogisticDx)    # nrequires complex install 
```

## Access the data
```{r read-data, echo = TRUE}
# file <- "./EpiData/metabolic_syndrome.dta"     #  use this if the file is on your computer
file <- "https://raw.githubusercontent.com/drkamarul/multivar_data_analysis/refs/heads/main/data/metabolic_syndrome.dta"
df4 <- import(file, trust  = TRUE)
summary(df4)
glimpse(df4)  # get an overview of the data
```

## Fix the data
```{r fix-data, echo=FALSE}
# change all chr variables to factor
df4 <- df4 %>% 
    mutate_if(is.character, as.factor)
glimpse(df4)

# Create new categorical variable from fbs (normal, impaired, diabetes)
df4 <- df4 %>%
  mutate(cat_fbs = cut(fbs, 
                       breaks = c(2.50 , 6.10, 28.01 ),
                       labels = c("Normal", "Diabetes")))
df4 %>% 
  count(cat_fbs)
glimpse(df4)

# Remove NAs from cat_fbs
df4 <- df4 %>%
  filter(!is.na(cat_fbs)) 
df4 %>%
  count(cat_fbs)

# Flip dirction of cat_fbs
#df4 <- df4 %>%
#  mutate(cat_fbs = fct_relevel(cat_fbs, 
#                               c("Diabetes", 'Impaired', 'Normal')))
# levels(df4$cat_fbs)


# Summary statistics
summary_stats <- df4 %>%
  dplyr::select(totchol, hpt, weight, cat_fbs) %>%
  tbl_summary(
    by = cat_fbs,  # Group by cat_fbs
    statistic = list(
      all_continuous() ~ "{mean} ({sd})"  # Mean and SD for continuous variables
      #all_continuous() ~ "{median} ({p25}, {p75})"  # Median and IQR
    ),
    digits = all_continuous() ~ 2,  # Round to 2 decimal places
    label = list(
      totchol ~ "Total Cholesterol (mg/dL)",
      hpt ~ "Hypertension Status",
      weight ~ "Weight (kg)"
    )
  ) %>%
  add_p() %>%  # Add p-values for group comparisons
  modify_caption("**Summary Statistics by Fasting Blood Sugar Category**")

summary_stats
```

## Multiple Logistic regression
```{r logistic_regression, echo=FALSE}
# Perform logistic regression
mlog_reg <- glm(cat_fbs ~ totchol + hpt + weight , data = df4, family = binomial(link = 'logit'))
#mlog_reg <- vglm(cat_fbs ~ totchol + hpt + weight, multinomial, data = df4, model = TRUE)
summary(mlog_reg)
```

## Model performance measures
```{r model-performance, echo=FALSE}
mlog_reg_perf <- vglm(cat_fbs ~ totchol + hpt + weight, multinomial, data = df4, model = TRUE)
# Get -2LL and AIC
minus_2LL_mlog_reg <- -2 * as.numeric(logLik(mlog_reg_perf))
AIC_valm <- AIC(mlog_reg_perf)

# Get Efron's R虏
efron <- PseudoR2(mlog_reg_perf, which = "Efron")
r2_valm <- as.numeric(efron)

# Disiplay the summary of the logistic regression model
summary(mlog_reg)
paste("R2= ",r2_valm)
```


## Calculate log OR
```{r calc-log_OR, echo = TRUE}
mlog_reg_tbl <- tbl_regression(mlog_reg, exponentiate = FALSE)
mlog_reg_tbl
```

## Calculate OR
```{r calc-OR, include=FALSE}
mlog_reg_OR <- tbl_regression(mlog_reg, exponentiate = TRUE)
mlog_reg_OR
```

## Combine logOR and OR results with model performance 
```{r log_reg_tbl, echo = TRUE}
combined_tbl_mlog_reg <- tbl_merge(
  tbls = list(mlog_reg_tbl, mlog_reg_OR),
  tab_spanner = c("**log Odds**", "**Odds Ratio**")  # Optional: Add spanning headers
) %>%
 as_gt() %>%
  tab_source_note(

    source_note = paste0("R虏 = ", round(r2_valm,3),
                          ", -2LL = ", round(minus_2LL_mlog_reg, 0), 
                          ", AIC = ", round(AIC_valm, 0)
                        )
  )

# Display the combined table
 combined_tbl_mlog_reg
```

## Goodness of fit
```{r , echo=FALSE}
mlog_reg_GOF <- gof(mlog_reg, g = 8)
# Estimate the log OR for death of each patient
predict_values <- augment(mlog_reg)
predict_values %>%
  slice(1:10)

predict_probs <- augment(mlog_reg, type.predict = "response")
predict_probs %>%
  slice(1:10)

# ROC analysis
df4 <- augment(mlog_reg, newdata = df4)
      colnames(df4)[colnames(df4) == ".fitted"] <- "pred_vlaues"
df4 <- augment(mlog_reg, newdata = df4, type.predict = "response")
      colnames(df4)[colnames(df4) == ".fitted"] <- "pred_probs"

pred_probs <- predict(mlog_reg, type = "response")

roc_obj <- roc(df4$pred_vlaues, df4$pred_probs)
auc(roc_obj)  
ci_auc <- ci.auc(roc_obj)
ci_auc

roc_df <- data.frame(
  fpr = 1 - roc_obj$specificities,
  tpr = roc_obj$sensitivities
)
ggplot(roc_df, aes(x = fpr, y = tpr)) +
  geom_line(color = "blue", size = 1.2) +
  geom_abline(linetype = "dashed", color = "gray") +  # Diagonal line
  labs(title = paste("ROC Curve (AUC =", round(auc(roc_obj), 3), ")"),
       x = "False Positive Rate (1 - Specificity)",
       y = "True Positive Rate (Sensitivity)") +
  theme_minimal()

# Hosmer-Lemeshow test
hoslem <- hoslem.test(df4$status, fitted(mlog_reg_simple), g = 10)
hoslem
```


### --------------------------------------


## Multiple Logistic regression /w inteaction term
```{r logistic_regression, echo=FALSE}
# Perform logistic regression
mlog_reg_ia <- vglm(cat_fbs ~ totchol + hpt + weight + totchol*weight , multinomial, data = df4, model = TRUE)
summary(mlog_reg_ia)
```

## Model performance measures
```{r model-performance, echo=FALSE}
# Get -2LL and AIC
minus_2LL_mlog_reg_ia <- -2 * as.numeric(logLik(mlog_reg_ia))
AIC(mlog_reg_ia)

# Calculate Efron's R虏
r2_values_ia <- PseudoR2(mlog_reg_ia, which = "all")
r2_valm_ia <- r2_values["Efron"]

# Disiplay the summary of the logistic regression model
summary(mlog_reg_ia)
r2_valm_ia
```


## Calculate log OR
```{r calc-log_OR, echo = TRUE}
mlog_reg_tbl_ia <- tbl_regression(mlog_reg_ia, exponentiate = FALSE)
mlog_reg_tbl_ia
```

## Calculate OR
```{r calc-OR, include=FALSE}
mlog_reg_OR_ia <- tbl_regression(mlog_reg_ia, exponentiate = TRUE)
mlog_reg_OR_ia
```

## Combine logOR and OR results with model performance 
```{r log_reg_tbl, echo = TRUE}
combined_tbl_mlog_reg_ia <- tbl_merge(
  tbls = list(mlog_reg_tbl_ia, mlog_reg_OR_ia),
  tab_spanner = c("**log Odds**", "**Odds Ratio**")  # Optional: Add spanning headers
) %>%
  as_gt() %>%
  tab_source_note(

    source_note = paste0("R虏 = ", round(r2_valm_ia,3),
                          ", -2LL = ", round(minus_2LL_mlog_reg_ia, 0), 
                          ", AIC = ", round(AIC(mlog_reg_ia), 0)
                        )
  )

# Display the combined table
combined_tbl_mlog_reg
```





















--------------------------------------------------------
### !!!    砖 拽抓 拽   !!! 



## Models comparison
```{r Models-comparison, include=FALSE}
# Use Anova to compare models based on chisq test
anova1_result <- anova(mlog_reg, log_reg, test = 'Chisq')
anova_df1 <- as.data.frame(anova1_result)
anova_df1
annova_summary1 <- anova_df1 %>%
  mutate(Model = rownames(anova_df1)) %>%
  select(Model, everything()) %>%
  gt() %>%
  tab_header(
    title = "Model Comparison (Likelihood Ratio Test)"
  ) %>%
  fmt_number(columns = where(is.numeric), decimals = 3)
annova_summary1

# Use only the siginificant variables from the larger model
mlog_reg_simple <- glm(status ~ gcs + stroke_type, data = df4, family = binomial(link = 'logit'))
anova2_result <- anova(log_reg1, mlog_reg_simple, test = 'Chisq')
anova_df2 <- as.data.frame(anova2_result)
anova_df2
annova_summary2 <- anova_df2 %>%
  mutate(Model = rownames(anova_df2)) %>%
  select(Model, everything()) %>%
  gt() %>%
  tab_header(
    title = "Model Comparison (Likelihood Ratio Test)"
  ) %>%
  fmt_number(columns = where(is.numeric), decimals = 3)
annova_summary2 
```

---------------------------------------------------------

## Do prediction
```{r OR, include=FALSE}
# Estimate the log OR for death of each patient
predict_values <- augment(mlog_reg_simple)
predict_values %>%
  slice(1:10)

predict_probs <- augment(mlog_reg_simple, type.predict = "response")
predict_probs %>%
  slice(1:10)
```

## Goodness of fit
```{r , echo=FALSE}
mlog_reg_simple_GOF <- gof(mlog_reg_simple, g = 8)

# ROC analysis
roc_obj <- roc(df4$status, fitted(mlog_reg_simple))
auc(roc_obj)  
ci_auc <- ci.auc(roc_obj)
ci_auc

roc_df <- data.frame(
  fpr = 1 - roc_obj$specificities,
  tpr = roc_obj$sensitivities
)
ggplot(roc_df, aes(x = fpr, y = tpr)) +
  geom_line(color = "blue", size = 1.2) +
  geom_abline(linetype = "dashed", color = "gray") +  # Diagonal line
  labs(title = paste("ROC Curve (AUC =", round(auc(roc_obj), 3), ")"),
       x = "False Positive Rate (1 - Specificity)",
       y = "True Positive Rate (Sensitivity)") +
  theme_minimal()

# Hosmer-Lemeshow test
hoslem <- hoslem.test(df4$status, fitted(mlog_reg_simple), g = 10)
hoslem
```


## classification table
```{r , echo=FALSE}
# Predict class labels based on a threshold of 0.5
cm <- confusionMatrix(as.factor(pred_class), as.factor(df4$status), positive = "1")

metrics_df <- data.frame(
  Metric = c("Accuracy", "Sensitivity", "Specificity", "Precision", "F1 Score"),
  Value = c(cm$overall["Accuracy"],
            cm$byClass["Sensitivity"],
            cm$byClass["Specificity"],
            cm$byClass["Precision"],
            cm$byClass["F1"])
)

# Convert the table to a matrix
cm_table <- cm$table

# Convert to a better display format (wide-style table)
cm_wide <- as.data.frame.matrix(cm_table)

# Rename rows and columns for clarity
colnames(cm_wide) <- paste("Obs.", colnames(cm_wide))
cm_wide <- cbind(`Predicted` = rownames(cm_wide), cm_wide)
rownames(cm_wide) <- NULL

cm_wide %>%
  gt() %>%
  tab_header(title = "Confusion Matrix") %>%
  fmt_number(everything(), decimals = 0)


metrics_df <- metrics_df %>%
  gt() %>%
  fmt_number(columns = "Value", decimals = 3) %>%
  tab_header(title = "Classification Metrics")

#combined_df <- rbind(cm_wide, metrics_df)

#combined_df %>%
#  gt() %>%
#  tab_header(title = "Confusion Matrix and Classification Metrics") %>%
#  fmt_number(columns = c("Actual 0", "Actual 1"), decimals = 3)
```
