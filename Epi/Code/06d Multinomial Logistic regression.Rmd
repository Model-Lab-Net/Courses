###
### name  :  专
### ID    : [住驻专 转注转 转]
### course: 驻 (HIT.ac.il)
### lesson: 专专住 住转 06   
### date  : 13/07/2025
###  
###   注砖转 专住 住转 注 转专 砖转 专转


## Reset memory
```{r setup-packages, include = FALSE}
rm(list = ls(all.names = TRUE))       #  Clear all data objects         Clear packages
lapply(paste("package:", names(sessionInfo()$otherPkgs), sep = ""), detach, character.only = TRUE, unload = TRUE, force = TRUE)           # Remove packages from memory
gc()                                  # Clear unused data from memory ("garbage cllection")
dev.off()                             # Reset the display output of R
q("no")                               # This will completely shutdown R terminal
```

## Load required packages
```{r load-packages, include = FALSE}  
options("install.lock"=FALSE)
if (!require("pacman")) install.packages("pacman") ; library(pacman)
pacman::p_load(
  Rcpp, devtools, gh, remotes,   # For installing packages/files online (like from GitHub)
  rio, here,              # File import and path support
  labelled, DT,           # deal with labels
  tidyverse,              # data management + ggplot2 graphics,
  broom,                  # For tidying model outputs
  dplyr,                  # For data manipulation
  gt,                     # Nice beuatiful tables
  gtsummary,              # summary statistics and tests
  nortest,                # Anderson-Darling test for normality
  ggplot2,                # For creating plots
  ggpubr,                 # For ggplot2 extensions
  DescTools,              # For statistical functions like skewness and kurtosis
  summarytools,           # to get a table of all summary statistics
  car,                    # For Levene's test and ANOVA
  lmtest,                 # do linear regression tests
  parameters,             # get standardized parameters/coefficients
  GGally,                 # to make a correlation matrix
  skimr,                  # get overview of data
  pROC,                   # For ROC analysis
  caret,                  # For confusion matrix and classification metrics
  ggeffects,              # To display the confusion matrix
  performance,            # For model performance metrics
  generalhoslem,          # For Hosmer-Lemeshow test for goodness of fit 
  # MASS,                   # For statistical functions (polr for ordinal regression)ordinal
  ordinal,                # For ordinal regression statistical functions 
  generalhoslem,          # For Hosmer-Lemeshow test for goodness of fit 
  ResourceSelection,      # For Hosmer-Lemeshow test for goodness of fit 
  VGAM,                   # for multinomial logistic regression
  cardx
              )
# Install/load flexplot
if (!require("flexplot", quietly = TRUE)) devtools::install_github("dustinfife/flexplot", ref = "logistic_plots")  ;  library(flexplot)
```

## Access the data
```{r read-data, echo = TRUE}
# file <- "./EpiData/06 metabolic_syndrome.rds"     #  use this if the file is on your computer
file <- "https://raw.githubusercontent.com/Model-Lab-Net/Courses/refs/heads/main/Epi/Data/06%20metabolic_syndrome.rds"
df4 <- import(file, trust  = TRUE)
# show variable translations to Hebrew in lables
labels <- data.frame(Variable = names(df4), Label = unlist(var_label(df4)))   ;   gt(labels)
glimpse(df4)               # get an overview of the data
```

## Summary statistics
```{r clean-data, echo = TRUE}
summary_stats <- df4 %>%
  dplyr::select(totchol, hpt, weight, fbs.cat) %>%
  tbl_summary(
    by = fbs.cat,  # Group by fbs.cat
    statistic = list(
      all_continuous() ~ "{mean} ({sd})"  # Mean and SD for continuous variables
      #all_continuous() ~ "{median} ({p25}, {p75})"  # Median and IQR
    ),
    digits = all_continuous() ~ 2,  # Round to 2 decimal places
    label = list(
      totchol ~ "Total Cholesterol (mg/dL)",
      hpt ~ "Hypertension Status",
      weight ~ "Weight (kg)"
    )
  ) %>%
  add_p() %>%  # Add p-values for group comparisons
  modify_caption("**Summary Statistics by Fasting Blood Sugar Category**")

summary_stats
```

## Multinomial Logistic regression
```{r logistic_regression, echo = TRUE}
# Perform Multinomial logistic regression
#mlog_reg <- glm(fbs.cat ~ totchol + hpt + weight , data = df4, family = binomial(link = 'logit'))
mlog_reg <- vglm(fbs.cat ~ totchol + weight + hpt, family = multinomial, data = df4, model = TRUE)
summary(mlog_reg)
```

## Model performance measures
```{r model-performance, echo = TRUE}
mlog_reg_perf <- vglm(fbs.cat ~ totchol + weight + hpt, family = multinomial, data = df4, model = TRUE)
# Get -2LL and AIC
minus_2LL_mlog_reg <- -2 * as.numeric(logLik(mlog_reg_perf))
AIC_valm <- AIC(mlog_reg_perf)

# Get Efron's R虏
efron <- PseudoR2(mlog_reg_perf, which = "Efron")
r2_valm <- as.numeric(efron)

# Disiplay the summary of the logistic regression model
summary(mlog_reg)
paste("R2= ",r2_valm)
```

## Calculate logOR and OR results with model performance 
```{r log_reg_tbl, echo = TRUE}
# Calculate log OR
mlog_reg_tbl <- tbl_regression(mlog_reg, exponentiate = FALSE)
# Calculate OR
mlog_reg_OR <- tbl_regression(mlog_reg, exponentiate = TRUE)

#Combine results
combined_tbl_mlog_reg <- tbl_merge(
  tbls = list(mlog_reg_tbl, mlog_reg_OR),
  tab_spanner = c("**log Odds**", "**Odds Ratio**")  # Optional: Add spanning headers
) %>%
 as_gt() %>%
  tab_source_note(
    source_note = paste0("R虏 = ", round(r2_valm,3),
                          ", -2LL = ", round(minus_2LL_mlog_reg, 0), 
                          ", AIC = ", round(AIC_valm, 0)
                        )
  )

# Display the combined table
 combined_tbl_mlog_reg
```


### --------------------------------------


## Multiple multinomial Logistic regression /w inteaction term
```{r logistic_regression, echo = TRUE}
# Perform logistic regression
mlog_reg_ia <- glm(fbs.cat ~ totchol*weight + hpt, data = df4, family = binomial(link = 'logit'))
summary(mlog_reg_ia)
```

## Model performance measures
```{r model-performance, echo = TRUE}
# Get -2LL and AIC
mlog_reg_ia_perf <- vglm(fbs.cat ~ totchol + hpt + weight + totchol*weight , multinomial, data = df4, model = TRUE)
minus_2LL_mlog_reg_ia <- -2 * as.numeric(logLik(mlog_reg_ia_perf))
AIC_val_ia <- AIC(mlog_reg_ia_perf)

# Calculate Efron's R虏
r2_values_ia <- PseudoR2(mlog_reg_ia_perf, which = "Efron")
r2_valm_ia <- as.double(r2_values_ia)

# Disiplay the summary of the logistic regression model
summary(mlog_reg_ia)
paste("R2= ",r2_valm_ia)
```

## Combine logOR and OR results with model performance 
```{r log_reg_tbl, echo = TRUE}
# Calculate log OR
mlog_reg_tbl_ia <- tbl_regression(mlog_reg_ia, exponentiate = FALSE)
# Calculate OR
mlog_reg_OR_ia <- tbl_regression(mlog_reg_ia, exponentiate = TRUE)

# combine results
combined_tbl_mlog_reg_ia <- tbl_merge(
  tbls = list(mlog_reg_tbl_ia, mlog_reg_OR_ia),
  tab_spanner = c("**log Odds**", "**Odds Ratio**")  # Optional: Add spanning headers
) %>%
  as_gt() %>%
  tab_source_note(

    source_note = paste0("R虏 = ", round(r2_valm_ia,3),
                          ", -2LL = ", round(minus_2LL_mlog_reg_ia, 0), 
                          ", AIC = ", round(AIC(mlog_reg_ia), 0)
                        )
  )

# Display the combined table
combined_tbl_mlog_reg_ia
```

## Classification table
```{r log_reg-pred, echo = TRUE}
# Calculate predicted probabilities
predicted_probs <- predict(mlog_reg, type = "response")
df4$predicted_prob_multi <- predict(mlog_reg_ia, type = "response")

# Use caret package to get classification table
confusion_matrix <- caret::confusionMatrix(data = as.factor(round(df4$predicted_prob_multi, 0)), reference = as.factor(df4$fbs.cat))
confusion_matrix

# Extract the confusion matrix table
cm_table <- as.data.frame(confusion_matrix$table)
colnames(cm_table) <- c("Predicted", "True", "Count")
cm_table <- cm_table %>%
  mutate(Percent = round(Count / sum(Count) * 100, 1))

# Plot confusion matrix as a heatmap
ggplot(data = cm_table, aes(x = Predicted, y = True, fill = Percent)) +
  geom_tile() +
  geom_text(aes(label = Percent), vjust = 0.5, color = "black") +
  scale_fill_gradient(low = "white", high = "blue") +
  theme_minimal() +
  labs(title = "Confusion Matrix", x = "Predicted", y = "True") +
  theme(axis.text.x = element_text(angle = 0, hjust = 1))

# Get cm metrics
cm_metrics_df <- data.frame(
  Metric = c("Accuracy", "PPV", "NPV", "Sensitivity", "Specificity", "Precision", "F1 Score"),
  Value = round(c(
    confusion_matrix$overall["Accuracy"],
    confusion_matrix$byClass["Pos Pred Value"],
    confusion_matrix$byClass["Neg Pred Value"],
    confusion_matrix$byClass["Sensitivity"],
    confusion_matrix$byClass["Specificity"],
    confusion_matrix$byClass["Precision"],
    confusion_matrix$byClass["F1"]
  ), 2)
)

cm_metrics_df %>%
  gt()
```

## Hosmer-Lemeshow test for GOF
```{r hosmer-lemeshow, echo = TRUE}
# Use ResourceSelection to get the HosmerLemeshow test result
hl_test <- hoslem.test(df4$fbs.cat, df4$predicted_prob_multi, g = 10)
hl_test
```





### -------------------------------------------------
## 转专-注爪

## 砖 1
```{r question-1, echo = TRUE}
# 

```

## 砖 2
```{r question-2, echo = TRUE}
# 

```

## 砖 3
```{r question-3, echo = TRUE}
# 

```









### source: https://bookdown.org/drki_musa/dataanalysis/multinomial-logistic-regression.html
###         https://github.com/drkamarul/multivar_data_analysis/tree/main/data

## Clean the data
```{r clean-data, echo = TRUE}
# Load the data
file <- "https://raw.githubusercontent.com/drkamarul/multivar_data_analysis/refs/heads/main/data/metabolic_syndrome.dta"
df4 <- import(file, trust  = TRUE)
#write.csv(df4, here("EpiData", "06 metabolic_syndrome.csv"))

# Clean up variable names
df <- clean_names(df)
names(df) <- gsub("_", ".", names(df))

# change all chr variables to factor
df4 <- df4 %>% 
    mutate_if(is.character, as.factor)
glimpse(df4)

# Create new categorical variable from fbs (normal, impaired, diabetes)
df4 <- df4 %>%
  mutate(fbs.cat = cut(fbs, 
                       breaks = c(2.50 , 6.10 , 6.90 , 28.01 ),
                       labels = c("normal","impaired", "diabetes")))
glimpse(df4)

# Remove NAs from fbs.cat
df4 <- df4 %>%
  filter(!is.na(fbs.cat)) 
df4 %>%
  count(fbs.cat)

# Flip dirction of fbs.cat
#df4 <- df4 %>%
#  mutate(fbs.cat = fct_relevel(fbs.cat, 
#                               c("Diabetes", 'Impaired', 'Normal')))
# levels(df4$fbs.cat)

# Check the updated dataset structure
glimpse(df4)

# Save as R data file
saveRDS(df4, here("EpiData", "06 metabolic_syndrome.rds"))
```

## Give variable explanations in labels
```{r labels, echo = TRUE}
attr(df4$codesub, "label") <- "拽"
attr(df4$age, "label") <- ""
attr(df4$hpt, "label") <- "驻专驻专转专"
attr(df4$smoking, "label") <- "注砖"
attr(df4$dmdx, "label") <- "dmdx"
attr(df4$height, "label") <- ""
attr(df4$weight, "label") <- "砖拽"
attr(df4$waist, "label") <- "转"
attr(df4$hip, "label") <- "转"
attr(df4$msbpr, "label") <- "转砖砖转 抓  住住"
attr(df4$mdbpr, "label") <- "转砖砖转 抓  住"
attr(df4$hba1c, "label") <- " 住专专"
attr(df4$fbs, "label") <- "专转 住专  专 爪"
attr(df4$mogtt1h, "label") <- "mogtt1h"
attr(df4$mogtt2h, "label") <- "mogtt2h"
attr(df4$totchol, "label") <- "住专"
attr(df4$ftrigliz, "label") <- "专爪专"
attr(df4$hdl, "label") <- "住专 "
attr(df4$ldl, "label") <- "住专 专注"
attr(df4$gender, "label") <- "专"
attr(df4$crural, "label") <- "crural"
attr(df4$fbs.cat, "label") <- "fct 专转 住专  专 爪"

labels <- data.frame(Variable = names(df4), Label = unlist(var_label(df4)))
gt(labels)
```          