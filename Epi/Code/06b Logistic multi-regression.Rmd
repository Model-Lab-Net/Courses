###
### name  : דוד בורג
### ID    : [מספר תעודת זהות]
### course: אפידמיולוגיה (HIT.ac.il)
### lesson: רגרסיה לוגיסטית 06   
### date  : 13/07/2025
###  
###  נלמד לעשות רגסיה לוגיסטית מרובה משתנים


## Reset memory
```{r setup-packages, include = FALSE}
rm(list = ls(all.names = TRUE))       # 👈 Clear all data objects        👇 Clear packages
lapply(paste("package:", names(sessionInfo()$otherPkgs), sep = ""), detach, character.only = TRUE, unload = TRUE, force = TRUE)           # Clear packages from memory
gc()                                  # Clear unused data from memory ("garbage cllection")
dev.off()                             # Reset the display output of R
q("no")                               # This will completely shutdown R terminal
```

## Load required packages
```{r load-packages, include false}
options("install.lock" = FALSE)
if (!require("pacman")) install.packages("pacman") ; library(pacman)
pacman::p_load(
  Rcpp, devtools, gh, remotes,   # For installing packages/files online (like from GitHub)
  rio, here,              # File import and path support
  labelled,               # deal with labels
  tidyverse,              # data management + ggplot2 graphics,
  broom,                  # For tidying model outputs
  dplyr,                  # For data manipulation
  gt,                     # Nice beuatiful tables
  gtsummary,              # summary statistics and tests
  nortest,                # Anderson-Darling test for normality
  ggplot2,                # For creating plots
  ggpubr,                 # For ggplot2 extensions
  DescTools,              # For statistical functions like skewness and kurtosis
  summarytools,           # to get a table of all summary statistics
  car,                    # For Levene's test and ANOVA
  lmtest,                 # do linear regression tests
  parameters,             # get standardized parameters/coefficients
  GGally,                 # to make a correlation matrix
  skimr,                  # get overview of data
  pROC,                   # For ROC analysis
  cvms, ggimage, rsvg,    # For confusion matrix and classification metrics
  ggeffects,              # To display the confusion matrix
  performance,            # For model performance metrics
  generalhoslem           # For Hosmer-Lemeshow test for goodness of fit 
              )
# Install/load flexplot
if (!require("flexplot", quietly = TRUE)) devtools::install_github("dustinfife/flexplot", ref = "logistic_plots")  ;  library(flexplot)
```

## Access the data
```{r read-data, echo=FALSE}
# file <- "./EpiData/04 stroke.rds"     # 👈 use this if the file is on your computer
file <- "https://raw.githubusercontent.com/Model-Lab-Net/Courses/refs/heads/main/Epi/Data/04%20stroke.rds"
df3 <- import(file, trust = TRUE)
# show variable translations to Hebrew in lables
labels <- data.frame(Variable = names(df3), Label = unlist(var_label(df3)))   ;   gt(labels)
glimpse(df3)               # get an overview of the data
```
## Multivariate logistic regression
```{r logistic_multi-reg, echo=FALSE}
# Perform logistic regression
mlog_reg <- glm(status ~ gcs + stroke.type + sex + dm + sbp + age, data = df3, family = binomial(link = "logit"))
```

## Plot data and model
```{r flexplot, echo = TRUE}
# use flexplot
flexplot(status ~ gcs + stroke.type | sex + age, data = df3, method = "logistic", se = F, ghost.line = "red", jitter = c(0.1, 0.1))
```

## Analyze the distribution of residuals
```{r residuals, echo = TRUE}
# Residuals analysis
visualize(mlog_reg)
```

## Model performance measures
```{r logistic_multi-reg, echo=FALSE}
# Get -2LL and AIC
minus_2LL_mlog_reg <- -2 * as.numeric(logLik(mlog_reg))
AIC_valm <- AIC(mlog_reg)

# Calculate Nagelkerke's R²
r2_valm <- PseudoR2(mlog_reg, which = "Nagelkerke")

# Chi-square statistic for the omnibus test
null_model <- glm(status ~ 1, data = df3, family = binomial(link = "logit")) # null model (intercept-only model)
model_perf <- anova(null_model, mlog_reg, test = "Chisq")
chi_sq <- model_perf$Deviance[2] # Chi-square statistic
p_val <- model_perf$`Pr(>Chi)`[2] # p-value

# Disiplay the summary of the logistic regression model
summary(mlog_reg)
paste("R²= ", r2_valm)
```

## Calculate log Odds and Odds Ratio
```{r OR, include=FALSE}
# Recalculate logistic regression for OR
mlog_reg_OR <- tbl_regression(mlog_reg, exponentiate = TRUE)
mlog_reg_summary <- tbl_regression(mlog_reg, exponentiate = FALSE)

mlog_combined_tbl <- tbl_merge(
  tbls = list(mlog_reg_summary, mlog_reg_OR),
  # tab_spanner = c("**1st Model**", "**2nd Model**")
) %>%
  as_gt() %>%
  tab_source_note(
    source_note = md(paste0(
      "R² = ", round(r2_valm, 3),
      ",  -2LL = ", round(minus_2LL_mlog_reg, 0),
      ",  AIC = ", round(AIC(mlog_reg), 0), "<br>",
      "  χ² = ", round(chi_sq, 0),
      ",  p = ", round(p_val, 3), "<br>"
    ))
  )

mlog_combined_tbl
```


### ------------------------------------------


## Add inreaction term
```{r OR, include=FALSE}
# Recalculate logistic regression for OR
mlog_reg_ia <- glm(status ~ gcs + stroke.type + gcs:stroke.type, data = df3, family = binomial(link = "logit"))
mlog_reg_ia
tidy(mlog_reg_ia)

mlog_reg_ia_table <- tbl_regression(
  mlog_reg_ia,
  exponentiate = TRUE # show odds ratios instead of log-odds
  #  label = list(
  #    gcs ~ "GCS",
  #    stroke.type ~ "Stroke Type",
  #    gcs:stroke.type ~ "GCS × Stroke Type"
  #  )
)

mlog_reg_ia_table
```

## Model comparison
```{r mdodel-comparison, echo = TRUE}
# Compare models
model.comparison(mlog_reg, mlog_reg_ia)
```

## Classification table
```{r , echo=FALSE}
# Calculate predicted probabilities and append to df
df3$predict_prob_multi <- predict(mlog_reg_ia, type = "response")
df3$predict.prob.multi <- as.integer(df3$predict_prob_multi > 0.5)
glimpse(df3)

# Calculate the "confusion_matrix"
cm <- confusion_matrix(targets = df3$status, predictions = df3$predict.prob)

# Plot the "confusion_matrix"
plot_confusion_matrix(cm)

# Display the "classification metrics"
cm_metrics <- select_metrics(cm)
cm_metrics <- cm_metrics %>%
  pivot_longer(cols = everything(),
               names_to = "Metric",
               values_to = "Value"
              )
cm_metrics <- as.data.frame(cm_metrics)
cm_metrics <- cm_metrics %>%
  mutate(across(where(is.numeric), ~ round(., 3)))
cm_metrics

cm_metrics %>%
  gt() 
```

## Hosmer-Lemeshow test for GOF
```{r , echo=FALSE}
# Use ResourceSelection to get the Hosmer–Lemeshow test result
hl_test <- hoslem.test(df3$status, df3$predicted_prob_multi, g = 10)
hl_test
```

## ROC curve and AUC (area under curve)
```{r mlog_reg-ROC,2 echo = TRUE}
roc_obj <- roc(df3$status, df3$predict.prob, levels=c("0", "1"), direction="<", plot=TRUE, col="red", , main="ROC Curve", lwd=2, grid=TRUE, print.auc=TRUE, font=2)
```


### ------------------------------------------





## Get better estimates for best model
```{r log_reg_ia-est, echo = TRUE}
estimates(mlog_reg_ia)
```





### -------------------------------------------------
## תרגול-עצמי

## שאלה 1
```{r question-1, echo = TRUE}
# 

```

## שאלה 2
```{r question-2, echo = TRUE}
# 

```

## שאלה 3
```{r question-3, echo = TRUE}
# 

```









### source: https://bookdown.org/drki_musa/dataanalysis/binary-logistic-regression.html#multiple-binary-logistic-regression
###         https://github.com/drkamarul/multivar_data_analysis/tree/main/data

## Clean the data
```{r clean-data, echo = TRUE}
# Load the data
file <- "https://raw.githubusercontent.com/drkamarul/multivar_data_analysis/refs/heads/main/data/stroke.dta"
df3 <- import(file, trust = TRUE)
#write.csv(df3, here("EpiData", "04 stroke.csv"))

# Clean up variable names
df3 <- clean_names(df3)
names(df3) <- gsub("_", ".", names(df3))

# Convert status to integer (2 -> 0, 1 -> 1)
df3 <- df3 %>%
  mutate(
    status = ifelse(status == 2, 0, 1),
    sex = ifelse(sex == 2, 0, 1)
  )

# Convert these variables from dbl to int
df3 <- df3 %>%
  mutate(across(c(sex, status, dm, stroke.type), as.integer))

# Check the updated dataset structure
glimpse(df3)

# Save as R data file
saveRDS(df3, here("EpiData", "04 stroke.rds"))
```

## Give variable explanations in labels
```{r labels, echo = TRUE}
attr(df3$sex, "label") <- "מגדר"
attr(df3$status, "label") <- "מצב (חי / נפטר)"
attr(df3$gcs, "label") <- "סולם התרדמת של גלאזגו"
attr(df3$sbp, "label") <- "לחץ דם סיסטולי"
attr(df3$dm , "label") <- "סוּכֶּרֶת"
attr(df3$age, "label") <- "גיל"
attr(df3$stroke.type, "label") <- "סוג שבץ מוח (HS / IS)"

labels <- NULL
labels <- data.frame(Variable = names(df3), Label = unlist(var_label(df3)))
gt(labels)
```