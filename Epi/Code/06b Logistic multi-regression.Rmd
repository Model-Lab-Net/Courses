###
### name  :  专
### ID    : [住驻专 转注转 转]
### course: 驻 (HIT.ac.il)
### lesson: 专专住 住转 06   
### date  : 13/07/2025
###  
###   注砖转 专住 住转 专 砖转


## Reset memory
```{r setup-packages, include false}
rm(list = ls(all.names = TRUE))       #  Remove all data objects         Remove packages
lapply(paste("package:", names(sessionInfo()$otherPkgs), sep = ""), detach, character.only = TRUE, unload = TRUE, force = TRUE)           # Remove packages from memory
gc()                                  # Remove unused data from memory ("garbage cllection")
dev.off()                             # Reset the display output of R
q("no")                               # This will completely shutdown R terminal
```

## Load required packages
```{r load-packages, include false}
options("install.lock" = FALSE)
if (!require("pacman")) install.packages("pacman")
library(pacman)
pacman::p_load(
  Rcpp, devtools, gh, remotes,   # For installing packages/files online (like from GitHub)
  rio, here,              # File import and path support
  tidyverse,              # data management + ggplot2 graphics,
  broom,                  # For tidying model outputs
  dplyr,                  # For data manipulation
  gt,                     # Nice beuatiful tables
  gtsummary,              # summary statistics and tests in beautiful tables
  nortest,                # Anderson-Darling test for normality
  ggplot2,                # For creating plots
  DescTools,              # For statistical functions like skewness and kurtosis
  janitor,                # adding totals and percents to tables
  psych,                  # to get a table of all summary statistics
  car,                    # For Levene's test and ANOVA
  gtsummary,              # summary statistics and tests in beautiful tables
  corrr,                  # correlation
  lmtest,                 # linear regression tets
  parameters,             # calculate standardized parameters/coefficients
  GGally,                 # to make a correlation matrix
  skimr,                  # get overview of data
  pROC,                   # For ROC analysis
  performance,            # For model performance metrics
  caret,                  # For confusion matrix and classification metrics
  ggeffects,              # To display the confusion matrix
  ResourceSelection       # For Hosmer-Lemeshow test for goodness of fit 
              )
# Install/load flexplot
if (!require("flexplot", quietly = TRUE)) devtools::install_github("dustinfife/flexplot", ref = "logistic_plots")  ;  library(flexplot)
```

## Access the data
```{r read-data, echo=FALSE}
# file <- "./EpiData/04 stroke.rds"     #  use this if the file is on your computer
file <- "https://raw.githubusercontent.com/Model-Lab-Net/Courses/refs/heads/main/Epi/Data/04%20stroke.rds"
df3 <- import(file, trust = TRUE)
summary(df3)
skim(df3)                           # get an overview of the data
glimpse(df3)
```
## Multivariate logistic regression
```{r logistic_multi-reg, echo=FALSE}
# Perform logistic regression
mlog_reg <- glm(status ~ gcs + stroke.type + sex + dm + sbp + age, data = df3, family = binomial(link = "logit"))
```

## Plot data and model
```{r flexplot, echo = TRUE}
# use flexplot
flexplot(status ~ gcs + stroke.type | sex + age, data = df3, method = "logistic", se = F, ghost.line = "red", jitter = c(0.1, 0.1))
```

## Analyze the distribution of residuals
```{r residuals, echo = TRUE}
# Residuals analysis
visualize(mlog_reg)
```

## Model performance measures
```{r logistic_multi-reg, echo=FALSE}
# Get -2LL and AIC
minus_2LL_mlog_reg <- -2 * as.numeric(logLik(mlog_reg))
AIC_valm <- AIC(mlog_reg)

# Calculate Nagelkerke's R虏
r2_valm <- PseudoR2(mlog_reg, which = "Nagelkerke")

# Chi-square statistic for the omnibus test
null_model <- glm(status ~ 1, data = df3, family = binomial(link = "logit")) # null model (intercept-only model)
model_perf <- anova(null_model, mlog_reg, test = "Chisq")
chi_sq <- model_perf$Deviance[2] # Chi-square statistic
p_val <- model_perf$`Pr(>Chi)`[2] # p-value

# Disiplay the summary of the logistic regression model
summary(mlog_reg)
paste("R虏= ", r2_valm)
```

## Calculate log Odds and Odds Ratio
```{r OR, include=FALSE}
# Recalculate logistic regression for OR
mlog_reg_OR <- tbl_regression(mlog_reg, exponentiate = TRUE)
mlog_reg_summary <- tbl_regression(mlog_reg, exponentiate = FALSE)

mlog_combined_tbl <- tbl_merge(
  tbls = list(mlog_reg_summary, mlog_reg_OR),
  # tab_spanner = c("**1st Model**", "**2nd Model**")
) %>%
  as_gt() %>%
  tab_source_note(
    source_note = md(paste0(
      "R虏 = ", round(r2_valm, 3),
      ",  -2LL = ", round(minus_2LL_mlog_reg, 0),
      ",  AIC = ", round(AIC(mlog_reg), 0), "<br>",
      "  虏 = ", round(chi_sq, 0),
      ",  p = ", round(p_val, 3), "<br>"
    ))
  )

mlog_combined_tbl
```


### ------------------------------------------


## Add inreaction term
```{r OR, include=FALSE}
# Recalculate logistic regression for OR
mlog_reg_ia <- glm(status ~ gcs + stroke.type + gcs:stroke.type, data = df3, family = binomial(link = "logit"))
mlog_reg_ia
tidy(mlog_reg_ia)

mlog_reg_ia_table <- tbl_regression(
  mlog_reg_ia,
  exponentiate = TRUE # show odds ratios instead of log-odds
  #  label = list(
  #    gcs ~ "GCS",
  #    stroke.type ~ "Stroke Type",
  #    gcs:stroke.type ~ "GCS  Stroke Type"
  #  )
)

mlog_reg_ia_table
```

## classification table
```{r , echo=FALSE}
# Calculate predicted probabilities and append to df
df3$predicted_prob_multi <- predict(mlog_reg, type = "response")

# Use caret package to get classification table
confusion_matrix <- caret::confusionMatrix(data = as.factor(round(df3$predicted_prob_multi, 0)), reference = as.factor(df3$status))
confusion_matrix

# Extract the confusion matrix table
cm_table <- as.data.frame(confusion_matrix$table)
colnames(cm_table) <- c("Predicted", "True", "Count")
cm_table <- cm_table %>%
  mutate(Percent = round(Count / sum(Count) * 100, 1))

# Plot confusion matrix as a heatmap
ggplot(data = cm_table, aes(x = Predicted, y = True, fill = Percent)) +
  geom_tile() +
  geom_text(aes(label = Percent), vjust = 0.5, color = "black") +
  scale_fill_gradient(low = "white", high = "blue") +
  theme_minimal() +
  labs(title = "Confusion Matrix", x = "Predicted", y = "True") +
  theme(axis.text.x = element_text(angle = 0, hjust = 1))

# Get cm metrics
cm_metrics_df <- data.frame(
  Metric = c("Accuracy", "PPV", "NPV", "Sensitivity", "Specificity", "Precision", "F1 Score"),
  Value = round(c(
    confusion_matrix$overall["Accuracy"],
    confusion_matrix$byClass["Pos Pred Value"],
    confusion_matrix$byClass["Neg Pred Value"],
    confusion_matrix$byClass["Sensitivity"],
    confusion_matrix$byClass["Specificity"],
    confusion_matrix$byClass["Precision"],
    confusion_matrix$byClass["F1"]
  ), 2)
)
cm_metrics_df

cm_metrics_df %>%
  gt()
```

## Hosmer-Lemeshow test for GOF
```{r , echo=FALSE}
# Use ResourceSelection to get the HosmerLemeshow test result
hl_test <- hoslem.test(df3$status, df3$predicted_prob_multi, g = 10)
hl_test
```

## ROC curve and AUC (area under curve)
```{r mlog_reg-ROC,2 echo = TRUE}
roc_obj <- roc(df3$status, df3$predicted_prob_multi)

# Plot ROC curve
plot(roc_obj, col = "blue", main = "ROC Curve")

# Print AUC (AUC > 0.7)
auc(roc_obj)
```


### ------------------------------------------


## Model comparison
```{r mdodel-comparison, echo = TRUE}
model.comparison(mlog_reg, mlog_reg_ia)
```


## Get better estimates for best model
```{r log_reg_ia-est, echo = TRUE}
estimates(mlog_reg_ia)
```





### -------------------------------------------------
## 转专-注爪

## 砖 1
```{r question-1, echo = TRUE}
# 

```

## 砖 2
```{r question-2, echo = TRUE}
# 

```

## 砖 3
```{r question-3, echo = TRUE}
# 

```









### source: https://bookdown.org/drki_musa/dataanalysis/binary-logistic-regression.html#multiple-binary-logistic-regression
###         https://github.com/drkamarul/multivar_data_analysis/tree/main/data

## Clean the data
```{r clean-data, echo = TRUE}
# Load the data
file <- "https://raw.githubusercontent.com/drkamarul/multivar_data_analysis/refs/heads/main/data/stroke.dta"
df3 <- import(file, trust = TRUE)

# Clean up variable names
df3 <- clean_names(df3)
names(df3) <- gsub("_", ".", names(df3))

# Convert status to integer (2 -> 0, 1 -> 1)
df3 <- df3 %>%
  mutate(
    status = ifelse(status == 2, 0, 1),
    sex = ifelse(sex == 2, 0, 1)
  )

# Convert these variables from dbl to int
df3 <- df3 %>%
  mutate(across(c(sex, status, dm, stroke.type), as.integer))

# Check the updated dataset structure
glimpse(df3)

# Save as R data file
saveRDS(df3, here("EpiData", "04 stroke.rds"))
```