###
### name  : __________________
### ID    : [מספר תעודת זהות]
### course: אפידמיולוגיה (HIT.ac.il)
### lesson: רגרסיה לוגיסטית 06   
### date  : 13/07/2025
###  
###  נלמד לעשות רגסיה לוגיסטית מרובה משתנים


## Reset memory
```{r setup-packages, include = FALSE}
rm(list = ls(all.names = TRUE))          # 👈 Clear all data objects        👇 Clear packages
lapply(paste("package:", names(sessionInfo()$otherPkgs), sep = ""), detach, character.only = TRUE, unload = TRUE, force = TRUE)
gc()                                     # Clear unused data from memory ("garbage cllection")
dev.off()                                # Reset the display output of R
system("powershell -Command Clear-Host") # This will clear the terminal in VScode
```

## Load required packages
```{r load-packages, include false}
options("install.lock" = FALSE)
if (!require("pacman")) install.packages("pacman") ; library(pacman)
pacman::p_load(
  Rcpp, devtools, gh, remotes,   # For installing packages/files online (like from GitHub)
  rio, here,              # File import and path support
  labelled,               # deal with labels
  tidyverse,              # data management + ggplot2 graphics,
  broom,                  # For tidying model outputs
  dplyr,                  # For data manipulation
  gt,                     # Nice beuatiful tables
  gtsummary,              # summary statistics and tests
  nortest,                # Anderson-Darling test for normality
  ggplot2,                # For creating plots
  ggpubr,                 # For ggplot2 extensions
  DescTools,              # For statistical functions like skewness and kurtosis
  summarytools,           # to get a table of all summary statistics
  car,                    # For Levene's test and ANOVA
  lmtest,                 # do linear regression tests
  parameters,             # get standardized parameters/coefficients
  GGally,                 # to make a correlation matrix
  skimr,                  # get overview of data
  pROC,                   # For ROC analysis
  cvms, ggimage, rsvg,    # For confusion matrix and classification metrics
  ggeffects,              # To display the confusion matrix
  performance,            # For model performance metrics
  generalhoslem,          # For Hosmer-Lemeshow test for goodness of fit 
  rms
              )
# Install/load flexplot
if (!require("flexplot", quietly = TRUE)) devtools::install_github("dustinfife/flexplot", ref = "logistic_plots")  ;  library(flexplot)
```

## Access the data
```{r read-data, echo=FALSE}
# file <- "./EpiData/04 stroke.rds"     # 👈 use this if the file is on your computer
file <- "https://raw.githubusercontent.com/Model-Lab-Net/Courses/refs/heads/main/Epi/Data/04%20stroke.rds"
df3 <- import(file, trust = TRUE)
# show variable translations to Hebrew in lables
labels <- data.frame(Variable = names(df3), Label = unlist(var_label(df3)))   ;   gt(labels)
glimpse(df3)               # get an overview of the data
```

## Multivariate logistic regression
```{r logistic_multi-reg, echo=FALSE}
# Perform a multivariate logistic regression
mlog_reg <- glm(status ~ gcs + stroke.type + sex + age, data = df3, family = binomial(link = "logit"))
summary(mlog_reg)

dd <- datadist(df3)   ;   options(datadist = "dd")
mlog_reg_ <- lrm(status ~ gcs, data = df3)     # need this for model diagnostics. sorry.
```

## Plot data and model
```{r flexplot, echo = TRUE}
# use flexplot
flexplot(status ~ gcs + stroke.type | sex + age, data = df3, method = "logistic", se = F, ghost.line = "red", jitter = c(0.1, 0.1))
```

## Analyze the distribution of residuals
```{r residuals, echo = TRUE}
# Residuals analysis
visualize(mlog_reg)
```

## Model performance measures
```{r logistic_multi-reg, echo=FALSE}
# NEW way
minus2LL <- -2 * as.numeric(logLik(mlog_reg))  # -2 Log Likelihood
AIC_val  <- AIC(mlog_reg)                      # AIC
r2_val   <- mlog_reg_$stats["R2"]               # R² (is multiple R², usually "R²" is Nagelkerke)
chi_sq   <- mlog_reg_$stats["Model L.R."]       # Omnibus Chi-square (Likelihood Ratio Chi²)
p_val    <- mlog_reg_$stats["P"]                # Omnibus test p-value (Likelihood Ratio Test)
```

## Calculate log Odds and Odds Ratio
```{r OR, include=FALSE}
# Recalculate logistic regression for OR
mlog_reg_OR <- tbl_regression(mlog_reg, exponentiate = TRUE) %>%
  modify_header(estimate ~ "**Odds ratio**")
mlog_reg_summary <- tbl_regression(mlog_reg, exponentiate = FALSE) %>%
  modify_header(estimate ~ "**log Odds**")

mlog_combined_tbl <- tbl_merge(
  tbls = list(mlog_reg_summary, mlog_reg_OR),
  # tab_spanner = c("**1st Model**", "**2nd Model**")
) %>%
  as_gt() %>%
  tab_source_note(
    source_note = md(paste0(
      "R² = ", round(r2_val, 3),
      ",  -2LL = ", round(minus2LL, 0),
      ",  AIC = ", round(AIC_val, 0), "<br>",
      "  χ² = ", round(chi_sq, 0),
      ",  p = ", round(p_val, 3), "<br>"
    ))
  )

mlog_combined_tbl
```


### ------------------------------------------


## Add inreaction term
```{r OR, include=FALSE}
# Recalculate logistic regression for OR
mlog_reg_ia <- glm(status ~ gcs + stroke.type:sex, data = df3, family = binomial(link = "logit"))
summary(mlog_reg_ia)

mlog_reg_ia_ <- lrm(status ~ gcs + stroke.type*sex, data = df3)

mlog_reg_ia_table <- tbl_regression(
  mlog_reg_ia,
  exponentiate = TRUE, # show odds ratios instead of log-odds
  tidy_fun = broom.helpers::tidy_parameters
) %>%
  modify_header(estimate ~ "**Odds ratio**")

mlog_reg_ia_table
```

## Model comparison
```{r mdodel-comparison, echo = TRUE}
# Compare models
model.comparison(mlog_reg, mlog_reg_ia)
```

## Classification table
```{r , echo=FALSE}
# Calculate predicted probabilities and append to df
df3$predict.prob.multi <- predict(mlog_reg_ia, type = "response")
df3$predict.class.multi <- as.integer(df3$predict.prob.multi > 0.5)
glimpse(df3) 

# Calculate the "confusion_matrix"
cm <- confusion_matrix(targets = df3$status, predictions = df3$predict.class.multi)

# Plot the "confusion_matrix"
plot_confusion_matrix(cm)

# Get the "classification metrics"
cm_metrics <- select_metrics(cm) %>%
  # convert all columns to numeric (if needed)
  mutate(across(everything(), as.numeric)) %>%
  # pivot to long format directly
  pivot_longer(
    cols = everything(),
    names_to = "Metric",
    values_to = "Value"
  ) %>%
  # round numeric values
  mutate(Value = round(Value, 3))

cm_metrics

# Display in a nice table
cm_metrics %>%
  gt() 
```

## Hosmer-Lemeshow test for GOF
```{r , echo=FALSE}
# Get the Hosmer–Lemeshow test using generalhoslem
hl_test <- logitgof(df3$status, df3$predict.prob, g=10)
hl_test
```

## ROC curve and AUC (area under curve)
```{r mlog_reg-ROC,2 echo = TRUE}
roc_obj <- roc(response = df3$status, 
               predictor = df3$predict.prob,
               direction = "<", 
               plot = TRUE, 
               col = "red",
               lwd = 2,
               grid = TRUE,
               print.auc = TRUE,
               main = "ROC Curve",
               font = 2)
```


## Get better estimates for best model
```{r log_reg_ia-est, echo = TRUE}
estimates(mlog_reg_ia)
```





### -------------------------------------------------
## תרגול-עצמי

## שאלה 1
```{r question-1, echo = TRUE}
# 

```

## שאלה 2
```{r question-2, echo = TRUE}
# 

```

## שאלה 3
```{r question-3, echo = TRUE}
# 

```









### source: https://bookdown.org/drki_musa/dataanalysis/binary-logistic-regression.html#multiple-binary-logistic-regression
###         https://github.com/drkamarul/multivar_data_analysis/tree/main/data

## Clean the data
```{r clean-data, echo = TRUE}
# Load the data
file <- "https://raw.githubusercontent.com/drkamarul/multivar_data_analysis/refs/heads/main/data/stroke.dta"
df3 <- import(file, trust = TRUE)
#write.csv(df3, here("EpiData", "04 stroke.csv"))

# Clean up variable names
df3 <- clean_names(df3)
names(df3) <- gsub("_", ".", names(df3))

# Convert status to integer (2 -> 0, 1 -> 1)
df3 <- df3 %>%
  mutate(
    status = ifelse(status == 2, 0, 1),
    sex = ifelse(sex == 2, 0, 1)
  )

# Convert these variables from dbl to int
df3 <- df3 %>%
  mutate(across(c(sex, status, dm, stroke.type), as.integer))

# Check the updated dataset structure
glimpse(df3)

# Save as R data file
saveRDS(df3, here("EpiData", "04 stroke.rds"))
```

## Give variable explanations in labels
```{r labels, echo = TRUE}
attr(df3$sex, "label") <- "מגדר"
attr(df3$status, "label") <- "מצב (חי / נפטר)"
attr(df3$gcs, "label") <- "סולם התרדמת של גלאזגו"
attr(df3$sbp, "label") <- "לחץ דם סיסטולי"
attr(df3$dm , "label") <- "סוּכֶּרֶת"
attr(df3$age, "label") <- "גיל"
attr(df3$stroke.type, "label") <- "סוג שבץ מוח (HS / IS)"

labels <- NULL
labels <- data.frame(Variable = names(df3), Label = unlist(var_label(df3)))
gt(labels)
```